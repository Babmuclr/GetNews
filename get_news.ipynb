{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib import request  # urllib.requestモジュールをインポート\n",
    "from bs4 import BeautifulSoup  # BeautifulSoupクラスをインポート\n",
    "import lxml\n",
    "from newspaper import Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-22\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt \n",
    "now = dt.datetime.utcnow()\n",
    "now -= dt.timedelta(days=1)\n",
    "year, month, day = now.year, now.month, now.day\n",
    "limit_date = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
    "date = str(year) + \"-\" + str(month)\n",
    "print(limit_date) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_names = [\" - Reuters\", \" - Bloomberg\", \" - CNBC\", \" - TheStreet\", \" - Fox Business\"]\n",
    "website_names_2 = [\"Reuters\", \"Bloomberg\", \"CNBC\", \"TheStreet\", \"Fox Business\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(stock=\"Apple\", date=\"2021-11-24\", homepage=\"reuters.com\"):\n",
    "    stock = urllib.parse.quote(stock)\n",
    "    url = \"https://news.google.com/rss/search?q=\" + stock +  \"+after:\" + date + \"+inurl:\" + homepage + \"&hl=en-US&gl=US&ceid=US:en\"\n",
    "    response = request.urlopen(url)\n",
    "    soup = BeautifulSoup(response,\"xml\")\n",
    "    response.close()\n",
    "    elems = soup.find_all(\"item\")\n",
    "    return elems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./news_site.txt\") as f:\n",
    "    news_sites = f.readlines()\n",
    "news_sites = list(map(lambda x: x[:-1],news_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./stocks.txt\") as f:\n",
    "    stocks = f.readlines()\n",
    "stocks = list(map(lambda x: x[:-1],stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for news_site, website_name, website_name_2 in zip(news_sites, website_names, website_names_2 ):\n",
    "    items = get_items(stock=\"\", date=limit_date, homepage=news_site)\n",
    "    for item in items[:5]:\n",
    "        title = item.find(\"title\").getText()\n",
    "        title = str(title.replace(website_name,\"\"))\n",
    "        link = item.find(\"link\").getText()\n",
    "        pubdate = item.find(\"pubDate\").getText()\n",
    "        source = website_name_2\n",
    "        # data = [title,link,pubdate,source]\n",
    "        articles.append(\n",
    "            {\n",
    "                \"title\": title,\n",
    "                \"pubDate\": pubdate,\n",
    "                \"source\": source,\n",
    "                \"link\": link,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "cred = credentials.Certificate(\"./serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib.parse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_time = 1\n",
    "try_max_count = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translated_text(from_lang, to_lang, from_text):\n",
    "     \n",
    "    # urlencode\n",
    "    from_text = urllib.parse.quote(from_text)\n",
    "     \n",
    "    #　url作成\n",
    "    url = 'https://www.deepl.com/translator#' + from_lang +'/' + to_lang + '/' + from_text\n",
    "     \n",
    "    #　ヘッドレスモードでブラウザを起動\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "     \n",
    "    # ブラウザーを起動\n",
    "    driver = webdriver.Chrome('./chromedriver', options=options)\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)  # 見つからないときは、10秒まで待つ\n",
    " \n",
    " \n",
    "    for i in range(try_max_count):\n",
    "         \n",
    "        # 指定時間待つ\n",
    "        time.sleep(sleep_time)  \n",
    "        html = driver.page_source\n",
    "        to_text = get_text_from_page_source(html)\n",
    "         \n",
    "        try_count = i + 1\n",
    "     \n",
    "        if to_text:\n",
    "            wait_time =  sleep_time * try_count\n",
    "            print(str(wait_time) + \"秒\")\n",
    "             \n",
    "            # アクセス修了\n",
    "            break\n",
    "             \n",
    "    # ブラウザ停止\n",
    "    driver.quit()\n",
    "     \n",
    "    return to_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_page_source(html):\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    target_elem = soup.find(class_=\"lmt__translations_as_text__text_btn\")\n",
    "    text = target_elem.text\n",
    "     \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tencent hands shareholders $16.4 bln windfall in the form of JD.com stake\n",
      "Ant will be best among China's BAD bunch\n",
      "EXCLUSIVE Australia puts website accused of fake journalists on register for payment by Facebook, Google\n",
      "U.S. SEC rejects Apple bid to block shareholder proposal on forced labour -letter\n",
      "Philippines approves Merck's COVID-19 pill for at-risk patients\n",
      "Stock Market Today: Dow, S&P Live Updates for Dec. 23, 2021\n",
      "Omicron vs. Delta: Hospitalization Risk Is Far Lower With New Variant\n",
      "Eisai Plunges After Alzheimer Drug Fails to Win Japan Backing\n",
      "A Flotilla of U.S. LNG Cargoes Is Headed to Fuel-Starved Europe\n",
      "Europe's Power Crunch Shuts Down Factories as Prices Hit Record\n",
      "Asia-Pacific markets rise; JD shares in Hong Kong plunge 7% after Tencent says it will reduce stake\n",
      "SEC rejects Apple bid to block shareholder proposal on forced labor, letter shows\n",
      "Intel apologizes in China over Xinjiang supplier statement\n",
      "Stock futures rise as market attempts to extend comeback rally to a third day\n",
      "Gold firms above $1,800, set for second weekly rise\n",
      "Stocks Close Higher on Pfizer Covid-19 Treatment Approval, Economic News\n",
      "Cramer's Mad Money Recap 1222: Visa, Disney, Chipotle, Boeing\n",
      "Former Disney CEO Iger Leaves the Company and Won't Be Coming Back\n",
      "68 High Yield Bond ETFs Ranked For 2022\n",
      "Big Tech Legislation Faces Uphill Battle in Congress\n",
      "FDA authorizes first COVID-19 treatment pill, Pfizer's Paxlovin drug\n",
      "Was radio advertising the untold secret ingredient in Youngkin's Virginia victory?\n",
      "Farm owner, economist warns COVID shutdowns would increase prices and cause shortages\n",
      "Amazon reportedly took down reviews of Chinese president's book after demands\n",
      "Home loan prices hit second-highest level ever\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles = \"\"\n",
    "for article in articles:\n",
    "    article = article[\"title\"].replace(\"/\",\"\")\n",
    "    titles += (article+\"\\n\")\n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5秒\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "     \n",
    "    from_lang = 'en'\n",
    "    to_lang = 'ja'\n",
    "    #from_text = '提供された翻訳の正確性やサービスの利用可能性について、一切の責任を負いません。'\n",
    "    from_text = titles\n",
    " \n",
    "    # 翻訳\n",
    "    to_text = get_translated_text(from_lang, to_lang, from_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['オミクロン・バリアントがより多くの国で検出され、科学者たちが答えを探している オーストラリア', 'オニキス石炭火力発電所、オランダ政府の支援で閉鎖へ', '石油、ガス、太陽光発電への投資でリビアへの復帰を目指すシェル', 'マッコーリーと仏Engie、Fluenceでオーストラリアのバッテリーを構築', 'アマゾンのクラウド部門、インテルやNvidiaに対抗する新チップを発表', 'Software AG、30億ドル規模のハイテク企業の売却を検討していると言われる', 'Meta (FB)社の役員でDiemの共同開発者であるDavid Marcus氏が会社を去ることになりました。', '南アフリカでオミクロン・バリアントが発生。2歳未満の子供が病院の10％を占める', 'ユーロ圏のインフレ率、予想を上回る4.9％を記録', 'ワクチン競争をリードしてきたPfizer社が30年ぶりに最高の月を迎える', 'Cramer氏、火曜の下落で現金を投入することを提案「売るには遅すぎる', 'オミクロン恐怖症の拡大とパウエルのテーパリング発言でダウは650ポイント下落', 'アジア太平洋地域の株式は、オミクロンのコビットの変動を見守る投資家の影響でほとんどが下落、原油価格は反発', 'S&P 500、BidenがCovidのロックダウンは必要ないと発言したことで、金曜日の暴落から1.3%の反発。', 'サイバーマンデーのオンライン売上高は昨年比1.4％減の107億ドル、史上初のマイナスとなる', '市場の低迷で住宅価格が冷え込む', 'Z世代とミレニアル世代が直面する6つの大きなお金の問題', '今年のサイバーマンデーは購入者に13.9％の負担を強いた', 'バンク・オブ・アメリカ、Squareを中立に、Twitterを買いに変更', 'モデナ、リジェネロン・オミクロンの警告が米国の原油価格を9月の最安値に引きずり込む', 'Twitterの新CEO、Parag Agrawal氏とは？', 'ゴールドマン・サックスのCEOが高額な税金でニューヨーク市に警告', 'セールスフォースのベニオフ氏、共同CEOに就任', '陪審員は万引きで訴えられたWalmartの女性に210万ドルを与える', 'マテル社CEO、バイデン氏がホリデーシーズン中のサプライチェーン危機を解いてくれると「心強い」と感じる']\n"
     ]
    }
   ],
   "source": [
    "japanese_title = list(to_text.split(\"\\n\"))\n",
    "print(japanese_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(japanese_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(articles)):\n",
    "    articles[i][\"japanese_title\"] = japanese_title[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Omicron variant detected in more countries as scientists race to find answers Australia',\n",
       " 'pubDate': 'Sun, 28 Nov 2021 23:02:00 GMT',\n",
       " 'source': 'Reuters',\n",
       " 'link': 'https://www.reuters.com/world/new-coronavirus-variant-omicron-keeps-spreading-australia-detects-cases-2021-11-28/',\n",
       " 'japanese_title': 'オミクロン・バリアントがより多くの国で検出され、科学者たちが答えを探している オーストラリア'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in articles:\n",
    "    title = article[\"title\"]\n",
    "    hash_val = hashlib.sha224(title.encode()).hexdigest()\n",
    "    with open(\"./articles/importants/articles.txt\", \"r\") as f:\n",
    "        x = f.read()\n",
    "    hash_li = list(x.split(\"\\n\"))[:-1]\n",
    "    if hash_val not in hash_li:\n",
    "        with open(\"./articles/importants/articles.txt\", \"a\", newline=\"\") as f:\n",
    "            f.write(hash_val+\"\\n\")\n",
    "        doc_ref = db.collection(\"articles\").document()\n",
    "        doc_ref.set({\n",
    "            u\"title\": article[\"title\"],\n",
    "            u\"pubDate\": article[\"pubDate\"],\n",
    "            u\"link\": article[\"link\"],\n",
    "            u\"source\": article[\"source\"],\n",
    "            u\"title_ja\": article[\"japanese_title\"],  \n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
